<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Causal Bayesian Network</title>
      <link href="/2020/06/20/Causal-Bayesian-Network/"/>
      <url>/2020/06/20/Causal-Bayesian-Network/</url>
      
        <content type="html"><![CDATA[<p>[TOC]</p><h1 id="Bayesian-Network"><a href="#Bayesian-Network" class="headerlink" title="Bayesian Network"></a>Bayesian Network</h1><h2 id="贝叶斯定理"><a href="#贝叶斯定理" class="headerlink" title="贝叶斯定理"></a>贝叶斯定理</h2><p><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926372422123.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w447"></p><p><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926406771156.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w636"><br>参考链接：<a href="https://www.zhihu.com/question/19725590/answer/217025594" target="_blank" rel="noopener">https://www.zhihu.com/question/19725590/answer/217025594</a></p><h2 id="引入贝叶斯网络的原因"><a href="#引入贝叶斯网络的原因" class="headerlink" title="引入贝叶斯网络的原因"></a>引入贝叶斯网络的原因</h2><p>参考链接：<a href="https://zhuanlan.zhihu.com/p/33860572" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/33860572</a></p><blockquote><p>用于简化随机变量的联合概率分布的表现</p></blockquote><p><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926377253815.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w441"></p><p>贝叶斯网络（以及其他所有的概率图模型）相比于原始的联合分布模型，最大的优势在于增加了变量之间条件独立的先验信息，从而<strong>减小了模型的体积</strong>，与模型进行推断、学习的时间。例如，上图共有5个变量，如果用朴素的联合分布模型建模，条件概率表格的体积将会是 48 ，而采用贝叶斯网络后，条件概率表格的总体积为17 。</p><h2 id="贝叶斯网络解决的问题"><a href="#贝叶斯网络解决的问题" class="headerlink" title="贝叶斯网络解决的问题"></a>贝叶斯网络解决的问题</h2><ol><li>条件概率</li><li>最大后验概率</li></ol><h2 id="贝叶斯网络的相关定义及特性"><a href="#贝叶斯网络的相关定义及特性" class="headerlink" title="贝叶斯网络的相关定义及特性"></a>贝叶斯网络的相关定义及特性</h2><p>参考：Causality——Judea Pearl 2nd edition</p><h3 id="Markov-parents"><a href="#Markov-parents" class="headerlink" title="Markov parents"></a>Markov parents</h3><ol><li><p>定义：</p><p><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926378362656.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w554"></p><ul><li>即$PAi$是将$Xi$与其predecessor隔开的一组变量</li></ul></li><li><p>推论：DAG是贝叶斯网络的必要条件有：</p><ol><li><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926379743242.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w388"><ul><li>即每一个节点的概率只受其父节点的约束</li></ul></li></ol></li></ol><h3 id="Markov-Compatibility"><a href="#Markov-Compatibility" class="headerlink" title="Markov Compatibility"></a>Markov Compatibility</h3><blockquote><p> If a probability function $P$ admits the factorization of (1.33) relative to DAG $G$, we say that $G$ represents $P$, that $G$ and $P$ are compatible, or that <strong>$P$ is Markov relative to $G$</strong>.</p></blockquote><ul><li>通过知道所有变量的conditional independency，就描绘与G compatible的概率分布</li></ul><blockquote><p>A convenient way of characterizing the set o f distributions compatible with a DAG G is to <strong>list the set of (conditional) independencies that each such distribution must sat­isfy</strong>. These independencies can be read off the DAG by using a graphical criterion called <strong>d-separation</strong></p></blockquote><h3 id="Parental-Markov-Condition"><a href="#Parental-Markov-Condition" class="headerlink" title="Parental Markov Condition"></a>Parental Markov Condition</h3><ol><li>定义<ul><li><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926679316940.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w446"></li></ul></li></ol><h3 id="Ordered-Markov-Condition"><a href="#Ordered-Markov-Condition" class="headerlink" title="Ordered Markov Condition"></a>Ordered Markov Condition</h3><ol><li>定义<ul><li><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926683169335.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w451"></li></ul></li><li>A consequence of this theorem is <strong>an order-independent criterion</strong>  for determining whether a given probability P is Markov relative to a given DAG G.<ul><li>order-independent：由于同一张联合分布概率表可能对应多张贝叶斯图，某一个节点的predecessor排列也有多种，无论predecessor的排列如何都，该节点都与所有的predecessor节点独立</li></ul></li></ol><h3 id="Observational-Equivalence"><a href="#Observational-Equivalence" class="headerlink" title="Observational Equivalence"></a>Observational Equivalence</h3><ol><li>定义<ul><li><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926700374377.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w449"></li></ul></li><li>Two networks that are <strong>observationally equivalent</strong> cannot be distinguished <strong>without resorting to manipulative experimentation</strong> or temporal information<ol><li><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926700806785.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w384"><ul><li>X3:Sprinkler,X2:Rain</li></ul></li><li>将X1，X2中间的箭头逆转，不会破坏原有的V-structure/引入新的V-structure；因此X2/X1中箭头两个方向是observational equivalent。因此，X1和X2之间箭头的方向不能由probabilistic info得出</li><li>若对X2-X4箭头方向调整，则会破坏一个原有的V结构，X4-X5之间箭头方向调整，则会产生一个新的V结构</li></ol></li></ol><blockquote><p>Thus, we see that some probability functions P (such as the one responsi­ ble for the construction of the Bayesian network in above pic), when unaccompanied by temporal information，can <strong>constrain the directionality of some arrows in the graph</strong>.</p></blockquote><h3 id="Techniques-for-calculation"><a href="#Techniques-for-calculation" class="headerlink" title="Techniques for calculation"></a>Techniques for calculation</h3><ol><li>Message-passing architecture and Tree structure<ul><li>join-tree propagation:  decompose the network into clusters then form tree structure, each clusters is a compound variable that is capable of passing mes­sages to its neighbors<ul><li><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926702453659.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w345"></li></ul></li></ul></li><li><strong>Cut-set conditioning method</strong>(不太理解)<ul><li>a set of variables is instantiated (given specific values) such that the remaining network forms a tree.The propagation is then performed on that tree, and a new instantiation chosen, until all instantiations have been exhausted; <strong>the results are then averaged</strong></li></ul></li></ol><h3 id="Independency-in-BN"><a href="#Independency-in-BN" class="headerlink" title="Independency in BN"></a>Independency in BN</h3><p><strong>如何判断a与b的independency</strong>: 假如a发生变化，a变化的影响是否会传达到b</p><h4 id="Local-Independency"><a href="#Local-Independency" class="headerlink" title="Local Independency"></a>Local Independency</h4><blockquote><p> Any variable in the network is independent of its non-descendents given its parents.<br>$$ (X \perp NonDesc(X) | Pa(X) $$where $ NonDesc(X) $ is the set of variables which are not descendents of $ X $ and $ Pa(X) $ is the set of variables which are parents of $ X $.</p></blockquote><h4 id="Global-Independency"><a href="#Global-Independency" class="headerlink" title="Global Independency"></a>Global Independency</h4><h5 id="三种结构"><a href="#三种结构" class="headerlink" title="三种结构"></a>三种结构</h5><p>参考链接：<a href="https://zhuanlan.zhihu.com/p/30139208" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/30139208</a></p><h6 id="head-to-head-Common-Evidence"><a href="#head-to-head-Common-Evidence" class="headerlink" title="head-to-head(Common Evidence)"></a>head-to-head(Common Evidence)</h6><p><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926386359550.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w248"></p><ol><li>c已知<ul><li>a产生变化，c不变，那么b也要发生变化，因此a、b不独立</li><li>有：<ul><li>P(a,b|c)= P(a,b,c)/P(c)=P(a)P(b)P(c|a,b)/P(c)</li><li>无法得到P(a,b|c)=P(a|c)P(b|c)</li></ul></li></ul></li><li>c未知<ul><li>a、b被阻断（blocked），条件独立</li><li><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926387353186.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w356"></li></ul></li></ol><h6 id="tail-to-tail-Common-Cause-V-structure"><a href="#tail-to-tail-Common-Cause-V-structure" class="headerlink" title="tail-to-tail(Common Cause/V structure)"></a>tail-to-tail(Common Cause/V structure)</h6><p><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926389037966.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w247"></p><ol><li>c已知<ul><li>有：<ul><li>P(a,b,c)=P(c)<em>P(a|c)</em>P(b|c)</li><li>P(a,b|c)=P(a|c)P(b|c)</li></ul></li><li>a/b仅取决于c，a⊥b｜c</li></ul></li><li>c未知<ul><li>无法得出P(a,b) = P(a)P(b)，即c未知时，a、b不独立。</li></ul></li></ol><h6 id="head-to-tail"><a href="#head-to-tail" class="headerlink" title="head-to-tail"></a>head-to-tail</h6><p><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926391726520.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w302"></p><ol><li>c已知<ul><li>a的变化不会影响c，c的变化会影响b，因此a⊥b｜c</li></ul></li><li>c未知<ul><li>The influence flows from $ A $ to $ B $ when $ C $ is not observed</li><li>有：<ul><li>P(a,b,c)=P(a)<em>P(c|a)</em>P(b|c)</li><li>但无法推出P(a,b) = P(a)P(b)</li><li>即c未知时，a、b不独立。</li></ul></li></ul></li><li>xi+1的分布状态只和xi有关，和其他变量条件独立，这种顺次演变的随机过程，就叫做<strong>马尔科夫链（Markov chain）</strong></li></ol><h3 id="D-separation"><a href="#D-separation" class="headerlink" title="D-separation"></a>D-separation</h3><p>为了回答<strong>给定一个随机变量的集合Z，随机变量A与B之间是否条件独立</strong>这个问题，我们需要引入d分隔的概念</p><ul><li><p>A、B间存在d分隔：某个节点集合C能d分隔节点A与节点B，当且仅当：给定C时，A与B之间<strong>不存在有效路径（active path/active trail）</strong>，即A、B被C隔断（blocked），A、B条件独立。</p><ul><li>Active Trail: 若A的变化可以影响B，则A和B中存在active trail </li></ul></li><li><p>A、B间存在d联结：不存在d分隔</p></li><li><p>例子：</p><p>  <img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926396060892.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w423"></p></li></ul><p>《Causality》中是这样定义的：<br><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926680828518.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w445"><br>例子：<br><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926681044665.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w397"></p><ul><li>粉色标记处：collider的子节点已知会使collider所在的path unlocked，即此时X会影响Y</li></ul><h2 id="贝叶斯网络的创建"><a href="#贝叶斯网络的创建" class="headerlink" title="贝叶斯网络的创建"></a>贝叶斯网络的创建</h2><h3 id="生成贝叶斯网络初始顺序的重要性"><a href="#生成贝叶斯网络初始顺序的重要性" class="headerlink" title="生成贝叶斯网络初始顺序的重要性"></a>生成贝叶斯网络初始顺序的重要性</h3><ul><li>在构建贝叶斯网络的时候，会收到变量初始状态的影响<br><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926695528684.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w457"></li></ul><h3 id="Structure-Learning"><a href="#Structure-Learning" class="headerlink" title="Structure Learning"></a>Structure Learning</h3><ol><li><p>定义：</p><blockquote><p>The task of structure learning for Bayesian networks refers to <strong>learn the structure</strong> of the directed acyclic graph (DAG) <strong>from data</strong></p></blockquote></li><li><p>两种方式：</p><ul><li>score-based approach </li><li>constraint-based approach </li></ul></li></ol><h3 id="Parameter-learning"><a href="#Parameter-learning" class="headerlink" title="Parameter learning"></a>Parameter learning</h3><ol><li><p>定义 </p><blockquote><p>Parameter learning is the process of using data to <strong>learn the distributions</strong> of a Bayesian network or Dynamic Bayesian network.</p></blockquote><ul><li>Dynamic Bayesian network: 变量的概率分布会随时间发生变化<ul><li><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926401957668.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w463"></li></ul></li><li>在贝叶斯参数学习里，认为模型的参数不是一个确定的值，而是一个随机变量，且满足一定的分布。<strong>贝叶斯参数学习的过程就是根据已知的数据集D来估计参数的概率分布，再用得到的参数概率分布来计算随机变量X的后验概率分布</strong>。</li></ul></li><li><p>complete data的方法</p><ol><li>极大似然估计MLE<ul><li>概率是通过参数，推测事实；似然是根据事实，推测参数</li><li>通过不断优化参数，使得一个事件发生的概率尽可能大Maximize{P((x1,x2,x3….)|参数)}<ul><li><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926405152667.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w284"></li><li>为什么能变成连乘：因为MLE的独立同分布假设</li></ul></li><li>参考链接：<ul><li><a href="https://www.zhihu.com/question/24124998" target="_blank" rel="noopener">https://www.zhihu.com/question/24124998</a></li><li><a href="https://zhuanlan.zhihu.com/p/26614750" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/26614750</a></li></ul></li></ul></li><li>贝叶斯估计<ul><li>参考链接：<a href="https://zhuanlan.zhihu.com/p/61593112" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/61593112</a><ul><li><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926409339661.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w511"><ul><li>通常我们取后验分布的期望作为参数的估计值</li></ul></li><li>最大后验估计MAP：<ul><li>参考链接：<a href="https://zhuanlan.zhihu.com/p/61593112" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/61593112</a></li><li><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926410276275.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w717"></li></ul></li></ul></li></ul></li></ol></li><li><p>incomplete data的方法</p><ol><li>Expectation-Maximization algorithm</li><li>Robust Bayesian estimate</li><li>Monte-Carlo Method</li><li>Gaussian approximation method</li></ol></li></ol><h1 id="Causal-Bayesian-Network"><a href="#Causal-Bayesian-Network" class="headerlink" title="Causal Bayesian Network"></a>Causal Bayesian Network</h1><h2 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h2><p>肺癌分析实例： <a href="http://www.causality.inf.ethz.ch//data/LUCAS.html" target="_blank" rel="noopener">http://www.causality.inf.ethz.ch//data/LUCAS.html</a></p><h2 id="贝叶斯网络模型在Causal-Inference时的局限性"><a href="#贝叶斯网络模型在Causal-Inference时的局限性" class="headerlink" title="贝叶斯网络模型在Causal Inference时的局限性"></a>贝叶斯网络模型在Causal Inference时的局限性</h2><p>局限性：贝叶斯网络本身<strong>无法区分出因果的方向</strong>。例如，A←B←C与A→B→C的因果方向完全相反，但在贝叶斯网络的模型描述下，它们<strong>表达的概率分布和条件独立假设完全相同</strong>。</p><ul><li>贝叶斯网络中，A→B未必等同于A导致B</li><li>概率论「给定/已知随机变量Z」里的「给定/已知」<strong>只能用于表达观察，而非介入</strong>（介入即产生激励/影响）。<ul><li>参考“介入主义因果观”，简而言之就是因是激励，果是响应</li><li><strong>因果关系是不可逆/非对称的，但是相关性是可逆/对称的</strong></li></ul></li></ul><h3 id="马尔可夫等价类"><a href="#马尔可夫等价类" class="headerlink" title="马尔可夫等价类"></a>马尔可夫等价类</h3><p><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926397039859.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w441"></p><h2 id="The-philosophy-behind-caual-Bayesian-Networks"><a href="#The-philosophy-behind-caual-Bayesian-Networks" class="headerlink" title="The philosophy behind caual Bayesian Networks"></a>The philosophy behind caual Bayesian Networks</h2><blockquote><p>It seems that if conditional independence judgments are byproducts of stored causal relationships, then tapping and representing those relationships directly would be a more natural and more reliable way of expressing what we know or believe about the world. </p></blockquote><h2 id="Causal-network的优越性"><a href="#Causal-network的优越性" class="headerlink" title="Causal network的优越性"></a>Causal network的优越性</h2><ol><li>causal mod­els (assuming they are valid) are much more <strong>informative</strong> than probability models.<ol><li>A joint distribution tells us how probable events are and how probabilities would change with subsequent observations, but a causal model also tells us how these probabilities would change as a result of external interventions   </li></ol></li><li>模块性<ol><li>由于 parent-child 之间的稳定以及自治的物理机制. 在不改变其他变量之间分布的情况下, 单独改变一个 parent-child 之间的分布是有可能的 ( conceivable ) </li></ol></li></ol><h2 id="Causal-Bayesian-network和Bayesian-network区别"><a href="#Causal-Bayesian-network和Bayesian-network区别" class="headerlink" title="Causal Bayesian network和Bayesian network区别"></a>Causal Bayesian network和Bayesian network区别</h2><ol><li><strong>CBN中的操作是do/intervene，BN中的操作是observe，do可以得出直接因果关系，observe只能得出相关性</strong></li></ol><p><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926708137133.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w451"></p><h2 id="Definition-of-causal-Bayesian-network"><a href="#Definition-of-causal-Bayesian-network" class="headerlink" title="Definition of causal Bayesian network"></a>Definition of causal Bayesian network</h2><p>P($v$)是集合V上的概率分布<br>P$x$($v$)是定义在intervention do(X=$x$)上的概率分布<br><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926708906062.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w441"></p><ol><li>因果贝叶斯网络应该符合概率图模型的标准</li><li>对于干涉的部分，P(do(X=$x$))=1</li><li>被干涉变量的父节点的概率分布是不变的。（并且注意的一点:这里讲干涉的分布形式成功转换为了正常的概率分布形式）</li></ol><h2 id="Properties-of-Causal-Bayesian-network"><a href="#Properties-of-Causal-Bayesian-network" class="headerlink" title="Properties of Causal Bayesian network"></a>Properties of Causal Bayesian network</h2><p><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926711948178.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w459"></p><ul><li>truncated factorization：justify the deletion procedure<ul><li>deletion：在causal network中，do(X)相当于把X与其predecessor全部断开</li></ul></li></ul><p><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926710523759.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w433"></p><ul><li>保证observe的condition probability和do操作的一致</li><li>为什么要一致呢？？</li></ul><p><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926710877480.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w450"></p><ul><li>控制了$Vi$的直接原因$PAi$（一组令Vi independent of its predecessor的变量）,那么剩下的变量就不会影响$Vi$的概率分布</li><li>只有$Vi$的descendants的概率分布会受到do操作的影响</li></ul><h2 id="Causal-relationship-and-their-stability"><a href="#Causal-relationship-and-their-stability" class="headerlink" title="Causal relationship and their stability"></a>Causal relationship and their stability</h2><ol><li>为了检验$Xi$对$Xj$是否有causal influence，进行操作do(X=$Xi$)<ul><li>只有$Xi$的descendant会受到intervention的影响</li><li>计算P$xi$($Xj$), 看$Xj$的分布是否发生了变化，若发生了变化则说明$Xi$对$Xj$有causal influence</li></ul></li><li>causal relationship的稳定性<ul><li>因果关系是 ontological (存在论) 的, 即真实的因果关系不会根据环境(do-operator)的变化而变化. 即使我们队知识的认识(概率分布)发生了变化</li><li>概率关系是 epistemic (认识论) 的, 我们对事物的认识(概率分布)会随着环境的变化(do-operator)而变化</li></ul></li></ol><h2 id="一些概念"><a href="#一些概念" class="headerlink" title="一些概念"></a>一些概念</h2><h3 id="Markov-Blanket"><a href="#Markov-Blanket" class="headerlink" title="Markov Blanket"></a>Markov Blanket</h3><ol><li>MB包括：all parents, children, and spouses of the target（X）</li><li>一个节点的MB：contains all the variables that shield the node from the rest of the network.</li><li>MB is the only knowledge needed to predict the behavior of that node and its children</li><li>例子：<img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926418193843.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w835"></li></ol><h3 id="Markov-Process"><a href="#Markov-Process" class="headerlink" title="Markov Process"></a>Markov Process</h3><blockquote><p>a random process in which the future is independent of the past, given the present</p></blockquote><h3 id="do操作符"><a href="#do操作符" class="headerlink" title="do操作符"></a>do操作符</h3><p>do(X),相当于令x已知，将x与所有指向x的点断开</p><h2 id="Backdoor-Criteria"><a href="#Backdoor-Criteria" class="headerlink" title="Backdoor Criteria"></a>Backdoor Criteria</h2><h3 id="什么是存在干扰"><a href="#什么是存在干扰" class="headerlink" title="什么是存在干扰"></a>什么是存在干扰</h3><p><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926653674927.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w458"></p><h3 id="引入Backdoor-Criteria的原因"><a href="#引入Backdoor-Criteria的原因" class="headerlink" title="引入Backdoor Criteria的原因"></a>引入Backdoor Criteria的原因</h3><ul><li>为了便于在实验的时候选择控制变量，确定对哪些变量进行intervene<ul><li>在causal inference时，控制变量就是confounder（混淆变量）</li></ul></li><li>参考链接：<a href="https://blog.csdn.net/s1314_JHC/article/details/80790112" target="_blank" rel="noopener">https://blog.csdn.net/s1314_JHC/article/details/80790112</a><ul><li><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926656785543.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w720"></li></ul></li></ul><h3 id="Backdoor-Path"><a href="#Backdoor-Path" class="headerlink" title="Backdoor Path"></a>Backdoor Path</h3><blockquote><p> $A$’s backdoor path is a <strong>non-causal path from $A$ to $Y$</strong>. They are “backdoor” paths because they flow backwards out of A: all of these paths point into A.</p></blockquote><ul><li>删除所有以A为起点的path(frontdoor path)后，保留的就是backdoor path</li><li>backdoor path里存在confounder</li></ul><h4 id="两种backdoor-path结构"><a href="#两种backdoor-path结构" class="headerlink" title="两种backdoor path结构"></a>两种backdoor path结构</h4><ol><li>Common Causes<ul><li><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926659776902.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w247"></li><li>A是treatment，Y是outcome，X是confounder<ul><li>由于混淆表量confounder的存在，导致A-&gt;Y的因果关系受到影响   </li></ul></li></ul></li><li>M-bias<blockquote><p>This structure is typically used to represent a circumstance where a researcher <strong>observes T,Y,M(U,W unobserved)</strong></p><p>Clearly, <strong>the causal effect of T on Y is 0</strong> , which is also equal to the marginal association between T and Y</p><p>In order to test whether M is a confounder, one would ‘adjust M’, eg: including M in a regression or by matching units on similar values of M. Then the causal expectation between T &amp; Y is not 0. <strong>So M is a confounder</strong></p></blockquote></li></ol><ul><li><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926662438389.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w313"></li></ul><h4 id="unblocked-path-blocked-path"><a href="#unblocked-path-blocked-path" class="headerlink" title="unblocked path / blocked path"></a>unblocked path / blocked path</h4><p><img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926666744310.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w169"></p><ol><li>存在unblocked backdoor path，x未知，A和Y条件不独立，A和Y有两种关系<ul><li>$A$直接导致了$Y$(直接因果关系)</li><li>通过backdoor path，$A$对$Y$施加了影响</li></ul></li><li>存在blocked backdoor path，有两种情况<ol><li>control for or stratify a non-collider on that path,<ul><li>即已知X，A与Y条件独立</li></ul></li><li>backdoor path上存在collider，则这条路必blocked<br>  <img src="http://hellofromkira.oss-cn-beijing.aliyuncs.com/2020/06/21/15926669276786.jpg?x-oss-process=image/auto-orient,1/quality,q_90" alt="-w332"><ol><li>collider blocks the association between the variables that influence it.</li><li><strong>Condition on the collider opens the path between $X$ and $Y$,cause “Berkson’s paradox”</strong></li></ol></li></ol></li></ol><h4 id="Berkson’s-paradox"><a href="#Berkson’s-paradox" class="headerlink" title="Berkson’s paradox"></a>Berkson’s paradox</h4><ol><li><p>现象</p><blockquote><p>two values can statistically be negatively correlated even when they appear positively correlated in the population.</p></blockquote></li><li><p>产生原因</p><blockquote><p>caused by systematically observing some events more than others. If you know that X+Y must be within a certain range, then having a high X results in a lower Y, and vice versa.</p></blockquote><ul><li>X+Y 已知相当于上述的collider已知</li></ul></li><li><p>与confounder不一样！！confounder是在研究因果关系时的控制变量；而berkson paradox仅是一个现象</p></li></ol><h3 id="Definition-of-Backdoor-criterion"><a href="#Definition-of-Backdoor-criterion" class="headerlink" title="Definition of Backdoor criterion"></a>Definition of Backdoor criterion</h3><blockquote><p>An effect of A on Y is identifiable if either:</p><ol><li>No backdoor paths from A to Y</li><li>Measured covariates are sufficient to block all backdoor paths from A to Y</li></ol><p>Backdoor criterion is powerful because it can check:</p><ol><li>if there is confounding given this DAG </li><li>if it is possible to removing the confounding</li><li>what variables to condition on to eliminate the confounding</li></ol></blockquote><ul><li>简而言之，backdoor criterion用于检测A到Y是否有直接的因果关系</li><li>借助backdoor criterion可以给已知DAG消歧，确定唯一的因果关系</li></ul><h3 id="Backdoor-criterion-and-Ignorability"><a href="#Backdoor-criterion-and-Ignorability" class="headerlink" title="Backdoor criterion and Ignorability"></a>Backdoor criterion and Ignorability</h3><blockquote><p> Ignorability Assumption:</p><ul><li>no unmeasured confounders</li><li>no unblockable backdoor paths</li></ul><p>Suppose that we use the backdoor criterion and find that a set of variables X blocks all the backdoor paths. This implies the treatment assignment is conditionally <strong>ignorable</strong>: Y (a) ⫫A|X.</p></blockquote>]]></content>
      
      
      
        <tags>
            
            <tag> Causal Inference </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2020/06/19/hello-world/"/>
      <url>/2020/06/19/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
